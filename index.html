<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>OMMM 2025 Workshop</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <h1>Interdisciplinary Workshop on Observations of Misunderstood, Misguided and Malicious Use of Language Models: OMMM 2025</h1>

  <div class="section">
    <h2>Time and Place</h2>
    <p>The first Interdisciplinary Workshop on Observations of Misunderstood, Misguided and Malicious Use of Language Models (OMMM 2025) wil be held with the <a href="https://ranlp.org/ranlp2025/">RANLP 2025</a> conference in Varna, Bulgaria, on 11th of September 2025.</p>
  </div>
  <div class="section">
    <h2>Programme</h2>
    <p>09:00-09:15 Welcome and organisers' remarks</p>
    <p>09:15-10:00 Introduction - Grand Challenges of Misunderstood, Misguided and Malicious Use (Nanna Innie)</p>
  </div>
  <div class="section">
    <h2>Target Audience</h2>
    <p>We expect our workshop to appeal to an interdisciplinary group, including:</p>
    <ul>
      <li>NLP and AI researchers focused on responsible LLM use</li>
      <li>Psychologists exploring consciousness and perception in LLMs</li>
      <li>HCI researchers studying interaction and trust with LLMs</li>
      <li>Philosophers considering ethical questions</li>
    </ul>
  </div>
  <div class="section">
    <h2>Workshop Topic and Content</h2>
    <p>The use of Large Language Models (LLMs) pervades scientific practices in multiple disciplines beyond the NLP/AI communities. Alongside benefits for productivity and discovery, widespread use often entails misuse due to misalignment of values, lack of knowledge, or, more rarely, malice. LLM misuse has the potential to cause real harm in a variety of settings.</p>
    <p>Through this workshop, we aim to gather researchers interested in identifying and mitigating inappropriate and harmful uses of LLMs. We categorise the misuses of LLMs into three domains:</p>
    <ul>
      <li><strong>Misunderstood usages</strong>: Misrepresentation, improper explanation, or opaqueness of LLMs.</li>
      <li><strong>Misguided usages</strong>: Misapplication of LLMs where their utility is questionable or inappropriate.</li>
      <li><strong>Malicious usages</strong>: Use for misinformation, plagiarism, and adversarial attacks.</li>
    </ul>
    <p>Topics include:</p>
    <ul>
      <li><strong>Misunderstood use</strong> (and how to improve understanding):
        <ul>
          <li>Misrepresentation of LLMs (e.g., anthropomorphic language)</li>
          <li>Attribution of consciousness</li>
          <li>Interpretability</li>
          <li>Overreliance on LLMs</li>
        </ul>
      </li>
      <li><strong>Misguided use</strong> (and how to find alternatives):
        <ul>
          <li>Underperformance and inappropriate applications</li>
          <li>Structural limitations and ethical considerations</li>
          <li>Deployment without proper training or safeguards</li>
        </ul>
      </li>
      <li><strong>Malicious use</strong> (and how to mitigate it):
        <ul>
          <li>Adversarial attacks, jailbreaking</li>
          <li>Detection and watermarking of machine-generated content</li>
          <li>Generation of misinformation or plagiarism</li>
          <li>Bias mitigation and trust design</li>
        </ul>
      </li>
    </ul>
  </div>
  <div class="section">
        <h2>Call for Papers</h2>
    <p>We are pleased to invite submissions for the first Interdisciplinary Workshop on Observations of Misunderstood, Misguided and Malicious Use of Language Models (OMMM 2025). The workshop will be held with the RANLP 2025 conference in Varna, Bulgaria, on 11-13 September 2025.</p> 
    <p><b><u>Overview</u></b><br>
      The use of Large Language Models (LLMs) pervades scientific practices in multiple disciplines beyond the NLP/AI communities. Alongside benefits for productivity and discovery, widespread use often entails misuse due to misalignment of values, lack of knowledge, or, more rarely, malice. LLM misuse has the potential to cause real harm in a variety of settings. </p> 
      <p>Through this workshop, we aim to gather researchers interested in identifying and mitigating inappropriate and harmful uses of LLMs. These include misunderstood usages (e.g., misrepresentation of LLMs in the scientific literature); misguided usages (e.g., deployment of LLMs without adequate training or privacy safeguards); and malicious usages (e.g., generation of misinformation and plagiarism). Sample topics are listed below, but we welcome submissions on any domain related to the scope of the workshop.</p> 
    <p><b><u>Important Dates</u></b><br>
      Submission deadline <b>[NEW]</b>: <b>15 July 2025</b>, at 23:59 Anywhere on Earth<br>
      Notification of acceptance: 01 August 2025<br>
      Camera-ready papers due: 30 August 2025<br>
      Workshop dates: September 11, 12, or 13, 2025</p>
    <p><b><u>Submission Guidelines</u></b><br>
      Submissions will be accepted as short papers (4 pages) and as long papers (8 pages), plus additional pages for references. All submissions undergo a double-blind review, so they should not include any identifying information. Submissions should conform to the RANLP guidelines; for further information and templates, please see <a href="https://ranlp.org/ranlp2025/index.php/submissions/">the RANLP submission guidelines</a>.</p>
      <p>We welcome submissions from diverse disciplines, including NLP and AI, psychology, HCI, and philosophy. We particularly encourage reports on negative results that provide interesting perspectives on relevant topics.</p>
      <p>In-person presenters will be prioritised when selecting submissions to be presented at the workshop, but the workshop will take place in a hybrid format. Accepted papers will be included in the workshop proceedings in the ACL Anthology.</p>
      <p>Papers should be submitted on <a href="https://softconf.com/ranlp25/OMMM2025/">the RANLP conference system</a>.</p>
    <p>For any questions, please contact the organisers at <a href="mailto:ommm-workshop@googlegroups.com">ommm-workshop@googlegroups.com</a></p>
  </div>
  <div class="section">
    <h2>Organizers</h2>
    <ul>
      <li><strong>Piotr Przybyła, Universitat Pompeu Fabra</strong> (<a href="https://piotr.phd/">website</a>, piotr.przybyla@upf.edu)</li>
      <li><strong>Matthew Shardlow, Manchester Metropolitan University</strong> (<a href="https://www.mmu.ac.uk/staff/profile/dr-matthew-shardlow">website</a>, m.shardlow@mmu.ac.uk)</li>
      <li><strong>Clara Colombatto, University of Waterloo</strong> (<a href="https://colombattolab.com/">website</a>, clara.colombatto@uwaterloo.ca)</li>
      <li><strong>Nanna Inie, IT University of Copenhagen</strong> (<a href="https://www.nannainie.com/">website</a>, nans@itu.dk)</li>
    </ul>
  </div>

  <div class="section">
    <h2>Programme Committee</h2>
    <ol>
      <li>Alina Wróblewska (Polish Academy of Sciences)</li>
      <li>Ashley Williams (Manchester Metropolitan University)</li>
      <li>Azadeh Mohammadi (University of Salford)</li>
      <li>Clara Colombatto (University of Waterloo)</li>
      <li>Dariusz Kalociński (Polish Academy of Sciences)</li>
      <li>Julia Struß (Fachhochschule Potsdam)</li>
      <li>Lev Tankelevitch (Microsoft Research)</li>
      <li>Leon Derczynski (NVIDIA)</li>
      <li>Marcos Zampieri (George Mason University)</li>
      <li>Matthew Shardlow (Manchester Metropolitan University)</li>
      <li>Nael B. Abu-Ghazaleh (University of California, Riverside)</li>
      <li>Nanna Inie (IT University of Copenhagen)</li>
      <li>Nhung T. H. Nguyen (Johnson & Johnson)</li>
      <li>Nishat Raihan (George Mason University)</li>
      <li>Oluwaseun Ajao (Manchester Metropolitan University)</li>
      <li>Peter Zukerman (University of Washington)</li>
      <li>Piotr Przybyła (Universitat Pompeu Fabra)</li>
      <li>Samuel Attwood (Manchester Metropolitan University)</li>
      <li>Sergiu Nisioi (University of Bucharest)</li>
      <li>Xia Cui (Manchester Metropolitan University)</li>
    </ol>
  </div>

  <div class="section">
    <h2>Contact</h2>
    Email us at <a href="mailto:ommm-workshop@googlegroups.com">ommm-workshop@googlegroups.com</a>
  </div>
</body>
</html>
