<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>OMMM 2025 Workshop</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <h1>Welcome to the first Interdisciplinary Workshop on Observations of Misunderstood, Misguided and Malicious Use of Language Models: OMMM 2025</h1>

  <div class="section">
    <h2>Time and place</h2>
    <p>The RANLP 2025 workshops will be held in Varna, Bulgaria, on 11-13 September 2025.</p>
    <h2>Call for contributions: TBA</h2>
    <h2>Workshop Topic and Content</h2>
    <p>The use of Large Language Models (LLMs) pervades scientific practices in multiple disciplines beyond the NLP/AI communities. Alongside benefits for productivity and discovery, widespread use often entails misuse due to misalignment of values, lack of knowledge, or, more rarely, malice. LLM misuse has the potential to cause real harm in a variety of settings.</p>
    <p>Through this workshop, we aim to gather researchers interested in identifying and mitigating inappropriate and harmful uses of LLMs. We categorise the misuses of LLMs into three domains:</p>
    <ul>
      <li><strong>Misunderstood usages</strong>: Misrepresentation, improper explanation, or opaqueness of LLMs.</li>
      <li><strong>Misguided usages</strong>: Misapplication of LLMs where their utility is questionable or inappropriate.</li>
      <li><strong>Malicious usages</strong>: Use for misinformation, plagiarism, and adversarial attacks.</li>
    </ul>
    <p>Topics include:</p>
    <ul>
      <li><strong>Misunderstood use</strong> (and how to improve understanding):
        <ul>
          <li>Misrepresentation of LLMs (e.g., anthropomorphic language)</li>
          <li>Attribution of consciousness</li>
          <li>Interpretability</li>
          <li>Overreliance on LLMs</li>
        </ul>
      </li>
      <li><strong>Misguided use</strong> (and how to find alternatives):
        <ul>
          <li>Underperformance and inappropriate applications</li>
          <li>Structural limitations and ethical considerations</li>
          <li>Deployment without proper training or safeguards</li>
        </ul>
      </li>
      <li><strong>Malicious use</strong> (and how to mitigate it):
        <ul>
          <li>Adversarial attacks, jailbreaking</li>
          <li>Detection and watermarking of machine-generated content</li>
          <li>Generation of misinformation or plagiarism</li>
          <li>Bias mitigation and trust design</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="section">
    <h2>Target Audience</h2>
    <p>We expect our workshop to appeal to an interdisciplinary group, including:</p>
    <ul>
      <li>NLP and AI researchers focused on responsible LLM use</li>
      <li>Psychologists exploring consciousness and perception in LLMs</li>
      <li>HCI researchers studying interaction and trust with LLMs</li>
      <li>Philosophers considering ethical questions</li>
    </ul>
  </div>

  <div class="section">
    <h2>Organizers</h2>
    <ul>
      <li><strong>Piotr Przybyła</strong> (<a href="https://piotr.phd/">website</a>, piotr.przybyla@upf.edu)</li>
      <li><strong>Matthew Shardlow</strong> (<a href="https://www.mmu.ac.uk/staff/profile/dr-matthew-shardlow">website</a>, m.shardlow@mmu.ac.uk)</li>
      <li><strong>Clara Colombatto</strong> (<a href="https://colombattolab.com/">website</a>, clara.colombatto@uwaterloo.ca)</li>
      <li><strong>Nanna Inie</strong> (<a href="https://www.nannainie.com/">website</a>, nans@itu.dk)</li>
    </ul>
  </div>

  <div class="section">
    <h2>Programme Committee</h2>
    <ol>
      <li>Alberto Barrón-Cedeño (University of Bologna)</li>
      <li>Alina Wróblewska (Polish Academy of Sciences)</li>
      <li>Ashley Williams (Manchester Metropolitan University)</li>
      <li>Clara Colombatto (University of Waterloo)</li>
      <li>Dariusz Kalociński (Polish Academy of Sciences)</li>
      <li>Julia Struß (Fachhochschule Potsdam)</li>
      <li>Keeley Crocket (Manchester Metropolitan University)</li>
      <li>Lev Tankelevitch (Microsoft Research)</li>
      <li>Leon Derczynski (NVIDIA)</li>
      <li>Lifeng Han (University of Leiden)</li>
      <li>Matthew Shardlow (Manchester Metropolitan University)</li>
      <li>Moshe Glickman (University College London)</li>
      <li>Nael B. Abu-Ghazaleh (University of California, Riverside)</li>
      <li>Nanna Inie (IT University of Copenhagen)</li>
      <li>Nhung T. H. Nguyen (Johnson & Johnson)</li>
      <li>Peter Zukerman (University of Washington)</li>
      <li>Piotr Przybyła (Universitat Pompeu Fabra)</li>
      <li>Raghavendra Selvan (University of Copenhagen)</li>
      <li>Riza Batista-Navarro (University of Manchester)</li>
      <li>Samuel Attwood (Manchester Metropolitan University)</li>
      <li>Seun Ajao (Manchester Metropolitan University)</li>
      <li>Steve Fleming (University College London)</li>
      <li>Xia Cui (Manchester Metropolitan University)</li>
    </ol>
  </div>
</body>
</html>
