<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>OMMM 2025 Workshop</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <h1>Interdisciplinary Workshop on Observations of Misunderstood, Misguided and Malicious Use of Language Models: OMMM 2025</h1>

  <div class="section">
    <h2>Time and Place</h2>
    <p>The first Interdisciplinary Workshop on Observations of Misunderstood, Misguided and Malicious Use of Language Models (OMMM 2025) wil be held with the <a href="https://ranlp.org/ranlp2025/">RANLP 2025</a> conference in Varna, Bulgaria, on 11-13 September 2025.</p>
    <h2>Call for Papers:</h2>
    <p>We are pleased to invite submissions for the first Interdisciplinary Workshop on Observations of Misunderstood, Misguided and Malicious Use of Language Models (OMMM 2025). The workshop will be held with the RANLP 2025 conference in Varna, Bulgaria, on 11-13 September 2025.</p> 
    <p><b><u>Overview</u></b>
      The use of Large Language Models (LLMs) pervades scientific practices in multiple disciplines beyond the NLP/AI communities. Alongside benefits for productivity and discovery, widespread use often entails misuse due to misalignment of values, lack of knowledge, or, more rarely, malice. LLM misuse has the potential to cause real harm in a variety of settings. </p> 
      <p>Through this workshop, we aim to gather researchers interested in identifying and mitigating inappropriate and harmful uses of LLMs. These include misunderstood usages (e.g., misrepresentation of LLMs in the scientific literature); misguided usages (e.g., deployment of LLMs without adequate training or privacy safeguards); and malicious usages (e.g., generation of misinformation and plagiarism). Sample topics are listed below, but we welcome submissions on any domain related to the scope of the workshop.</p> 
    <p><b><u>Important Dates</u></b>
      Submission deadline: 6 July 2025, at 23:59 Anywhere on Earth
      Notification of acceptance: 31 July 2025
      Camera-ready papers due: 20 August 2025
      Workshop dates: September 11, 12, or 13, 2025</p>
    <p><b><u>Submission Guidelines</u></b>
      Submissions will be accepted as short papers (4 pages) and as long papers (8 pages), plus additional pages for references. All submissions undergo a double-blind review, so they should not include any identifying information. Submissions should conform to the RANLP guidelines; for further information and templates, please see https://ranlp.org/ranlp2025/index.php/submissions/</p>
      <p>We welcome submissions from diverse disciplines, including NLP and AI, psychology, HCI, and philosophy. We particularly encourage reports on negative results that provide interesting perspectives on relevant topics.</p>
      <p>In-person presentations are preferred, but the workshop will be in a hybrid format, and there will be options for online presentations. Accepted papers will be included in the workshop proceedings in the ACL Anthology.</p>
      <p>Papers should be submitted on the RANLP conference system at https://softconf.com/ranlp25/OMMM2025/</p>
    <p><b><u>Keynote Speaker</u></b>
      We are excited to have Dr. Stefania Druga as the keynote speaker for the inaugural OMMM workshop. Dr. Druga is a Research Scientist at Google DeepMind, where she designs novel multimodal AI applications.</p>
    <p>For any questions, please contact the organisers at ommm-workshop@googlegroups.com.</p>
    <h2>Workshop Topic and Content</h2>
    <p>The use of Large Language Models (LLMs) pervades scientific practices in multiple disciplines beyond the NLP/AI communities. Alongside benefits for productivity and discovery, widespread use often entails misuse due to misalignment of values, lack of knowledge, or, more rarely, malice. LLM misuse has the potential to cause real harm in a variety of settings.</p>
    <p>Through this workshop, we aim to gather researchers interested in identifying and mitigating inappropriate and harmful uses of LLMs. We categorise the misuses of LLMs into three domains:</p>
    <ul>
      <li><strong>Misunderstood usages</strong>: Misrepresentation, improper explanation, or opaqueness of LLMs.</li>
      <li><strong>Misguided usages</strong>: Misapplication of LLMs where their utility is questionable or inappropriate.</li>
      <li><strong>Malicious usages</strong>: Use for misinformation, plagiarism, and adversarial attacks.</li>
    </ul>
    <p>Topics include:</p>
    <ul>
      <li><strong>Misunderstood use</strong> (and how to improve understanding):
        <ul>
          <li>Misrepresentation of LLMs (e.g., anthropomorphic language)</li>
          <li>Attribution of consciousness</li>
          <li>Interpretability</li>
          <li>Overreliance on LLMs</li>
        </ul>
      </li>
      <li><strong>Misguided use</strong> (and how to find alternatives):
        <ul>
          <li>Underperformance and inappropriate applications</li>
          <li>Structural limitations and ethical considerations</li>
          <li>Deployment without proper training or safeguards</li>
        </ul>
      </li>
      <li><strong>Malicious use</strong> (and how to mitigate it):
        <ul>
          <li>Adversarial attacks, jailbreaking</li>
          <li>Detection and watermarking of machine-generated content</li>
          <li>Generation of misinformation or plagiarism</li>
          <li>Bias mitigation and trust design</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="section">
    <h2>Target Audience</h2>
    <p>We expect our workshop to appeal to an interdisciplinary group, including:</p>
    <ul>
      <li>NLP and AI researchers focused on responsible LLM use</li>
      <li>Psychologists exploring consciousness and perception in LLMs</li>
      <li>HCI researchers studying interaction and trust with LLMs</li>
      <li>Philosophers considering ethical questions</li>
    </ul>
  </div>

  <div class="section">
    <h2>Organizers</h2>
    <ul>
      <li><strong>Piotr Przybyła, Universitat Pompeu Fabra</strong> (<a href="https://piotr.phd/">website</a>, piotr.przybyla@upf.edu)</li>
      <li><strong>Matthew Shardlow, Manchester Metropolitan University</strong> (<a href="https://www.mmu.ac.uk/staff/profile/dr-matthew-shardlow">website</a>, m.shardlow@mmu.ac.uk)</li>
      <li><strong>Clara Colombatto, University of Waterloo</strong> (<a href="https://colombattolab.com/">website</a>, clara.colombatto@uwaterloo.ca)</li>
      <li><strong>Nanna Inie, IT University of Copenhagen</strong> (<a href="https://www.nannainie.com/">website</a>, nans@itu.dk)</li>
    </ul>
  </div>

  <div class="section">
    <h2>Programme Committee</h2>
    <ol>
      <li>Alberto Barrón-Cedeño (University of Bologna)</li>
      <li>Alina Wróblewska (Polish Academy of Sciences)</li>
      <li>Ashley Williams (Manchester Metropolitan University)</li>
      <li>Clara Colombatto (University of Waterloo)</li>
      <li>Dariusz Kalociński (Polish Academy of Sciences)</li>
      <li>Julia Struß (Fachhochschule Potsdam)</li>
      <li>Keeley Crocket (Manchester Metropolitan University)</li>
      <li>Lev Tankelevitch (Microsoft Research)</li>
      <li>Leon Derczynski (NVIDIA)</li>
      <li>Lifeng Han (University of Leiden)</li>
      <li>Matthew Shardlow (Manchester Metropolitan University)</li>
      <li>Moshe Glickman (University College London)</li>
      <li>Nael B. Abu-Ghazaleh (University of California, Riverside)</li>
      <li>Nanna Inie (IT University of Copenhagen)</li>
      <li>Nhung T. H. Nguyen (Johnson & Johnson)</li>
      <li>Peter Zukerman (University of Washington)</li>
      <li>Piotr Przybyła (Universitat Pompeu Fabra)</li>
      <li>Raghavendra Selvan (University of Copenhagen)</li>
      <li>Riza Batista-Navarro (University of Manchester)</li>
      <li>Samuel Attwood (Manchester Metropolitan University)</li>
      <li>Seun Ajao (Manchester Metropolitan University)</li>
      <li>Steve Fleming (University College London)</li>
      <li>Xia Cui (Manchester Metropolitan University)</li>
    </ol>
  </div>

  <div class="section">
    <h2>Contact</h2>
    Email us at <a href="mailto:ommm-workshop@googlegroups.com">ommm-workshop@googlegroups.com</a>
  </div>
</body>
</html>
